{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "\n",
    "import spacy\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stars_filepath = 'review_stars_rest_subset.txt'\n",
    "review_txt_filepath = 'review_text_rest_subset.txt'\n",
    "business_filepath = 'review_business_rest_subset.txt'\n",
    "user_filepath = 'review_user_rest_subset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            yield review.replace('\\\\n', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(filepath,review_number):\n",
    "    \"\"\"\n",
    "    retrieve a particular review index\n",
    "    from the reviews file and return it\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(it.islice(line_review(filepath),\n",
    "                          review_number, review_number+1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(stars_filepath) as f:\n",
    "    stars = f.readlines()\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "stars = [x.strip() for x in stars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(review_txt_filepath) as f:\n",
    "    texts = f.readlines()\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "texts = [x.strip() for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(business_filepath) as f:\n",
    "    business = f.readlines()\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "business = [x.strip() for x in business]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(user_filepath) as f:\n",
    "    user = f.readlines()\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "user = [x.strip() for x in user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570963 1570963 1570963 1570963\n"
     ]
    }
   ],
   "source": [
    "#test lengths, all should be the same\n",
    "print(len(stars), len(texts), len(business), len(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52810\n"
     ]
    }
   ],
   "source": [
    "bus_set = frozenset(business)\n",
    "print(len(bus_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169373\n"
     ]
    }
   ],
   "source": [
    "user_set = frozenset(user)\n",
    "print(len(user_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'Eox_Qq74oaFZ-YjthpHhBw', 'Aov96CM4FZAXeZvKtsStdA', 'N93EYZy9R0sdlEvubu94ig', 'I8rveLd-dl81u6c8YqAxmw', 'ZnxudK5ExgpfXs4bicS4IA', 'hjk3ox7w1akbEuOgTJ03Bw', 'a9aW5e731lplWGHUZ02-zQ', 'zgQHtqX0gqMw1nlBZl2VnQ', 'RtUvSWO_UZ8V3Wpj0n077w', '5r6-G9C4YLbC7Ziz57l3rQ', 'z8oIoCT1cXz7gZP5GeU5OA', '0W4lkclzZThpx3V65bVgig', 'oWTn2IzrprsRkPfULtjZtQ', '4_GIJk0tX3k0x0FcUv4sNA', '28adZ4lsuUeVB2aWzohK9g', 'PFPUMF38-lraKzLcTiz5gQ', 'zxJlg4XCHNoFy78WZPv89w', 'Xy74meQwdTnloAAyRC-4cg', 'XWTPNfskXoUL-Lf32wSk0Q'})\n"
     ]
    }
   ],
   "source": [
    "test_set = frozenset(business[1:20])\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make collased business text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_bus_filepath = \"collapsed_business_rest_subset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_test_filepath = \"collapsed_business_rest_subset_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 51min 35s, sys: 3.08 s, total: 1h 51min 38s\n",
      "Wall time: 1h 51min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#function to loop through all business ids, collapse all reviews for that business into one string\n",
    "if 1 == 0:\n",
    "    with codecs.open(all_bus_filepath, 'w', encoding='utf_8') as f:\n",
    "        for x in bus_set:\n",
    "            review_index = [i for i,j in enumerate(business) if j == x]\n",
    "            review_sub = [texts[ind] for ind in review_index]\n",
    "            review_out = ''.join(map(str, review_sub))\n",
    "            f.write(review_out + '\\n')\n",
    "            #print(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collapsed_business = LineSentence(all_bus_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.LineSentence at 0x7fa49e78e4a8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsed_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(all_bus_filepath) as f:\n",
    "    all_bus = f.readlines()\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "all_bus = [x.strip() for x in all_bus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52810"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_bus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(all_test_filepath) as f:\n",
    "    test_bus = f.readlines()\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "test_bus = [x.strip() for x in test_bus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_bus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make collapsed user text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_user_filepath = \"collapsed_user_rest_subset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 44min 44s, sys: 5.56 s, total: 5h 44min 49s\n",
      "Wall time: 5h 45min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#function to loop through all business ids, collapse all reviews for that business into one string\n",
    "if 1 == 0:\n",
    "    with codecs.open(all_user_filepath, 'w', encoding='utf_8') as f:\n",
    "        for x in user_set:\n",
    "            review_index = [i for i,j in enumerate(user) if j == x]\n",
    "            review_sub = [texts[ind] for ind in review_index]\n",
    "            review_out = ''.join(map(str, review_sub))\n",
    "            f.write(review_out + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Setup and define function for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper functions from modern nlp in python\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            yield review.replace('\\\\n', '\\n')\n",
    "            \n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_review in nlp.pipe(line_review(filename),\n",
    "                                  batch_size=10000, n_threads=4):\n",
    "        \n",
    "        for sent in parsed_review.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent\n",
    "                             if not punct_space(token)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sample_review(review_txt_filepath, review_number):\n",
    "    \"\"\"\n",
    "    retrieve a particular review index\n",
    "    from the reviews file and return it\n",
    "    \"\"\"\n",
    "    \n",
    "    return list(it.islice(line_review(review_txt_filepath),\n",
    "                          review_number, review_number+1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda_model_filepath = 'lda_model_eat_30'\n",
    "trigram_dictionary_filepath = 'trigram_dict_eat_30.dict'\n",
    "trigram_model_filepath = 'trigram_model_all_eat_30'\n",
    "bigram_model_filepath = 'bigram_model_all_eat_30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda = LdaMulticore.load(lda_model_filepath)\n",
    "trigram_dictionary = Dictionary.load(trigram_dictionary_filepath)\n",
    "trigram_model = Phrases.load(trigram_model_filepath)\n",
    "bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_names = {0: u'chinese',\n",
    "               1: u'thai',\n",
    "               2: u'healthy',\n",
    "               3: u'smell',\n",
    "               4: u'japanese',\n",
    "               5: u'toronto',\n",
    "               6: u'service',\n",
    "               7: u'experience',\n",
    "               8: u'asian soup',\n",
    "               9: u'grocery',\n",
    "               10: u'parking',\n",
    "               11: u'bar ambiance',\n",
    "               12: u'uk',\n",
    "               13: u'good service',\n",
    "               14: u'fun ambiance',\n",
    "               15: u'young',\n",
    "               16: u'comfort food',\n",
    "               17: u'greek',\n",
    "               18: u'high end',\n",
    "               19: u'hotwing',\n",
    "               20: u'breakfast',\n",
    "               21: u'sweet',\n",
    "               22: u'wine & dine',\n",
    "               23: u'pubs',\n",
    "               24: u'good taste',\n",
    "               25: u'na drinks',\n",
    "               26: u'desserts',\n",
    "               27: u'coffee shop',\n",
    "               28: u'mexican',\n",
    "               29: u'reviews',\n",
    "               30: u'new york',\n",
    "               31: u'general restaurant',\n",
    "               32: u'beach',\n",
    "               33: u'location',\n",
    "               34: u'happy hour',\n",
    "               35: u'amazing',\n",
    "               36: u'vietnamese',\n",
    "               37: u'time',\n",
    "               38: u'vas legas',\n",
    "               39: u'montreal',\n",
    "               40: u'deli',\n",
    "               41: u'buffet',\n",
    "               42: u'bbq',\n",
    "               43: u'french',\n",
    "               44: u'money',\n",
    "               45: u'street taco',\n",
    "               46: u'pizza',\n",
    "               47: u'airport & delivery',\n",
    "               48: u'burger & fries',\n",
    "               49: u'italian'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#topic_names_filepath = 'topic_names_eats_30.pkl'\n",
    "\n",
    "#with open(topic_names_filepath, 'wb') as f:\n",
    "#    pickle.dump(topic_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_review = get_sample_review(all_test_filepath, 6)\n",
    "#print(sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lda_description(sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_numbers = list(range(0,50))\n",
    "df_all_numbers = pd.DataFrame(columns =[\"topic_number\"])\n",
    "for topic_number in all_numbers:\n",
    "    df_all_numbers = df_all_numbers.append({\n",
    "     \"topic_number\": topic_number\n",
    "      }, ignore_index=True)\n",
    "\n",
    "\n",
    "df_topics = pd.DataFrame(columns =[\"topic_name\"])\n",
    "\n",
    "for topic_number in all_numbers:\n",
    "    df_topics = df_topics.append({\n",
    "     \"topic_name\": topic_names[topic_number]\n",
    "      }, ignore_index=True)\n",
    "#print(df_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_filepath = all_test_filepath\n",
    "\n",
    "test_df = pd.DataFrame(columns=[\"topic_name\", \"freq\", \"bus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_bus_lda_filepath = \"review_bus_lda.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlrognstad/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:486: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "CPU times: user 24.5 s, sys: 12.1 s, total: 36.5 s\n",
      "Wall time: 7.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#function to loop through all businesses and convert review to \n",
    "if 1 == 1:\n",
    "    with open(all_bus_lda_filepath, 'w') as f:\n",
    "        for busi in list(range(0,3)):\n",
    "            # parse the review text with spaCy\n",
    "            parsed_review = nlp(test_bus[busi])\n",
    "    \n",
    "            # lemmatize the text and remove punctuation and whitespace\n",
    "            unigram_review = [token.lemma_ for token in parsed_review\n",
    "                      if not punct_space(token)]\n",
    "    \n",
    "            # apply the first-order and secord-order phrase models\n",
    "            bigram_review = bigram_model[unigram_review]\n",
    "            trigram_review = trigram_model[bigram_review]\n",
    "    \n",
    "            # remove any remaining stopwords\n",
    "            trigram_review = [term for term in trigram_review\n",
    "                      if not term in spacy.lang.en.stop_words.STOP_WORDS]\n",
    "    \n",
    "            # create a bag-of-words representation\n",
    "            review_bow = trigram_dictionary.doc2bow(trigram_review)\n",
    "    \n",
    "            # create an LDA representation\n",
    "            review_lda = lda[review_bow]\n",
    "    \n",
    "            # sort with the most highly related topics first\n",
    "            review_lda = sorted(review_lda, key=lambda review_lda: -review_lda[1])\n",
    "        \n",
    "            bus = ''.join([list(x) for x in bus_set][busi])\n",
    "\n",
    "            df = pd.DataFrame(columns=[\"topic_number\", \"freq\"])\n",
    "\n",
    "            for topic_number, freq in review_lda:\n",
    "                df = df.append({\n",
    "                \"topic_number\": topic_number,\n",
    "                \"freq\":  round(freq, 4)\n",
    "                }, ignore_index=True)\n",
    "            #merge with complete topic list and replace na with zero\n",
    "            df_full = pd.merge(df_all_numbers, df, how='left', on=['topic_number'])\n",
    "            df_full = df_full.fillna(0)\n",
    "        \n",
    "            df_full['bus'] = bus\n",
    "\n",
    "            pivoted = df_full.pivot('bus', 'topic_number')\n",
    "        \n",
    "            one_row = pivoted.iloc[0]\n",
    "        \n",
    "            out = one_row.values.tolist()\n",
    "            out.insert(0, bus)\n",
    "            out2 = str(out)\n",
    "            out3 = re.sub(r\"[\\[ | \\]]\", \"\", out2)\n",
    "            \n",
    "            print(busi)\n",
    "           \n",
    "            f.write(out3)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>['1ylA7yyrMMUX1zcu5EqO4Q'</th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.0.1</th>\n",
       "      <th>0.0430000014603138</th>\n",
       "      <th>0.012299999594688416</th>\n",
       "      <th>0.0.2</th>\n",
       "      <th>0.018699999898672104</th>\n",
       "      <th>0.0.3</th>\n",
       "      <th>0.01209999993443489</th>\n",
       "      <th>0.0.4</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0.21</th>\n",
       "      <th>0.0.22</th>\n",
       "      <th>0.0284000001847744</th>\n",
       "      <th>0.0.23</th>\n",
       "      <th>0.034699998795986176</th>\n",
       "      <th>0.0.24</th>\n",
       "      <th>0.0.25</th>\n",
       "      <th>0.016499999910593033</th>\n",
       "      <th>0.0.26</th>\n",
       "      <th>0.0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['-OEIW0dO96-492qa_luxaw'</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.011500000022351742]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['ToNd6fEn_SvcQc1Fulsidg'</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1061</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1569</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ['1ylA7yyrMMUX1zcu5EqO4Q'     0.0   0.0.1   0.0430000014603138  \\\n",
       "0  ['-OEIW0dO96-492qa_luxaw'  0.0000  0.0155                  0.0   \n",
       "1  ['ToNd6fEn_SvcQc1Fulsidg'  0.0979  0.0000                  0.0   \n",
       "\n",
       "    0.012299999594688416   0.0.2   0.018699999898672104   0.0.3  \\\n",
       "0                 0.0117  0.0000                    0.0  0.0671   \n",
       "1                 0.0000  0.2166                    0.0  0.1061   \n",
       "\n",
       "    0.01209999993443489   0.0.4           ...             0.0.21   0.0.22  \\\n",
       "0                0.0279     0.0           ...             0.0109   0.0000   \n",
       "1                0.0163     0.0           ...             0.0000   0.1569   \n",
       "\n",
       "    0.0284000001847744   0.0.23   0.034699998795986176   0.0.24   0.0.25  \\\n",
       "0               0.0203      0.0                 0.0129      0.0      0.0   \n",
       "1               0.0000      0.0                 0.0161      0.0      0.0   \n",
       "\n",
       "    0.016499999910593033   0.0.26                    0.0]  \n",
       "0                 0.0168   0.0475   0.011500000022351742]  \n",
       "1                 0.0192   0.0000                    0.0]  \n",
       "\n",
       "[2 rows x 51 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_read = pd.io.parsers.read_csv(all_bus_lda_filepath,sep=\",\")\n",
    "test_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "out3 = re.sub(r\"[\\[ | \\]]\", \"\", out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'ToNd6fEn_SvcQc1Fulsidg',0.09790000319480896,0.0,0.0,0.0,0.21660000085830688,0.0,0.10610000044107437,0.016300000250339508,0.0,0.011699999682605267,0.014100000262260437,0.0,0.0,0.0,0.014700000174343586,0.0,0.01209999993443489,0.032999999821186066,0.0,0.0,0.0,0.0,0.0,0.020999999716877937,0.010400000028312206,0.0,0.021900000050663948,0.0,0.0,0.052000001072883606,0.0,0.03269999846816063,0.0,0.013899999670684338,0.0,0.0,0.0,0.04740000143647194,0.0,0.0,0.0,0.15690000355243683,0.0,0.0,0.016100000590085983,0.0,0.0,0.019200000911951065,0.0,0.0\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['1ylA7yyrMMUX1zcu5EqO4Q', 0.0, 0.0, 0.0430000014603138, 0.012299999594688416, 0.0, 0.018699999898672104, 0.0, 0.01209999993443489, 0.0, 0.017799999564886093, 0.0, 0.01889999955892563, 0.0, 0.010200000368058681, 0.0560000017285347, 0.0, 0.30070000886917114, 0.0, 0.0, 0.0, 0.02810000069439411, 0.0, 0.0, 0.03150000050663948, 0.0348999984562397, 0.0, 0.0, 0.0, 0.0, 0.07020000368356705, 0.0, 0.027400000020861626, 0.0, 0.02290000021457672, 0.0, 0.035100001841783524, 0.0, 0.05079999938607216, 0.025299999862909317, 0.0203000009059906, 0.0, 0.0, 0.0284000001847744, 0.0, 0.034699998795986176, 0.0, 0.0, 0.016499999910593033, 0.0, 0.0]\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2 = str(out)\n",
    "''.join(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlrognstad/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:486: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "busi =0\n",
    "parsed_review = nlp(all_bus[busi])\n",
    "unigram_review = [token.lemma_ for token in parsed_review\n",
    "                      if not punct_space(token)]\n",
    "bigram_review = bigram_model[unigram_review]\n",
    "trigram_review = trigram_model[bigram_review]\n",
    "trigram_review = [term for term in trigram_review\n",
    "    if not term in spacy.lang.en.stop_words.STOP_WORDS]\n",
    "review_bow = trigram_dictionary.doc2bow(trigram_review)\n",
    "review_lda = lda[review_bow]\n",
    "\n",
    "bus = ''.join([list(x) for x in bus_set][busi])\n",
    "\n",
    "df = pd.DataFrame(columns=[\"topic_number\", \"freq\"])\n",
    "\n",
    "for topic_number, freq in review_lda:\n",
    "    df = df.append({\n",
    "    \"topic_number\": topic_number,\n",
    "    \"freq\":  round(freq, 4)\n",
    "    }, ignore_index=True)\n",
    "#merge with complete topic list and replace na with zero\n",
    "df_full = pd.merge(df_all_numbers, df, how='left', on=['topic_number'])\n",
    "df_full = df_full.fillna(0)\n",
    "        \n",
    "df_full['bus'] = bus\n",
    "\n",
    "pivoted = df_full.pivot('bus', 'topic_number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"21\" halign=\"left\">freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_number</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1ylA7yyrMMUX1zcu5EqO4Q</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       freq                                                  \\\n",
       "topic_number             0    1    2       3    4    5    6    7    8    9    \n",
       "bus                                                                           \n",
       "1ylA7yyrMMUX1zcu5EqO4Q  0.0  0.0  0.0  0.0624  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                         ...                                                \\\n",
       "topic_number             ...     40   41   42      43      44   45      46   \n",
       "bus                      ...                                                 \n",
       "1ylA7yyrMMUX1zcu5EqO4Q   ...    0.0  0.0  0.0  0.0171  0.0269  0.0  0.0592   \n",
       "\n",
       "                                             \n",
       "topic_number                47   48      49  \n",
       "bus                                          \n",
       "1ylA7yyrMMUX1zcu5EqO4Q  0.0886  0.0  0.1216  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_row = pivoted.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1ylA7yyrMMUX1zcu5EqO4Q', 0.0, 0.0, 0.0, 0.06239999830722809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02630000002682209, 0.0674000009894371, 0.0, 0.023099999874830246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11969999969005585, 0.0, 0.21979999542236328, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06069999933242798, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.022199999541044235, 0.07370000332593918, 0.0, 0.0, 0.0, 0.017100000753998756, 0.026900000870227814, 0.0, 0.05920000001788139, 0.08860000222921371, 0.0, 0.12160000205039978]\n"
     ]
    }
   ],
   "source": [
    "out = one_row.values.tolist()\n",
    "out.insert(0, bus)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This place is so good. I work nearby and come here often for lunch.  Their menu is 7.49 for one veg & one meat & rice or noodles, 7.99 for two veg & one meat & rice or noodles, 8.49 for one veg & two meat & rice or noodles. They also offer salads (7.49 I believe).  The rice is amazing. They have a few different kinds, but I have only tried the Jambalayan kind. It's sort of spicy but SO delicious. It is, in fact, so good, I am not willing to try the other kinds. Instead of rice, you can also get noodles.  Their vegetables include home fries, corn, mixed veggies, zucchini, mashed potatoes, and a few others. I have tried the home fries, mixed veggies, and zucchini and they are all good, but I personally like the home fries the most.  Their meats change on a daily basis, but they normally have bourbon chicken, blackened chicken, honey glazed chicken, spicy beef, rainbow shrimp, a type of fish (I forget), and a few other chicken flavours. The bourbon chicken is amazing. Ask for extra sauce over your rice.   The women here work fast, and will give you a sample if you are unsure of what you want. The servings are quite large. I find it's not the regular 'greasy Chinese food' you normally get, and instead, is probably decently healthy (you're in a food court, it's relative).   The drinks are a bit expensive, so that's why they get 4 stars. If you can, buy your food here and then go to KFC or somewhere to get a cheaper drink. I also wish the meals were about 50 cents cheaper. It's still good food for the price, so I won't complain too much. Definitely give it a try.Came here around 8:30pm which is when they start offering their end of day special.  I the Blackened fish, battered shrimp, mango salad and fried rice combo box $6.29.  The fish was very good.  Nice pepper taste and moist.  Mango salad was good too.  Shrimp was over cooked and fried rice was bland.  If you want cheap Cajun and Chinese meal then this is the place for you.\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DGwDXazeFcD7DByweszpFA'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([list(x) for x in bus_set][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
