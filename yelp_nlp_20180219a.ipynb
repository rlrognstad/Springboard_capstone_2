{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#regular spacy instal lwould not work, had to get from github\n",
    "#conda install -c conda-forge spacy\n",
    "#python -m spacy download en\n",
    "#check with: python -m spacy validate\n",
    "#restart jupyter notebook\n",
    "\n",
    "import codecs\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()\n",
    "#import en_core_web_md\n",
    "#nlp = en_core_web_md.load()\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I live very near this place and have been curious to try it for sometime now as it always seems busy.\n",
      "\n",
      "Well my curiosity has been satisfied and I'm sure I'll never feel the need to visit this place again.\n",
      "\n",
      "It struck me as a typical trendy place that yuppies feel they need to visit as all the other yuppies do.  \n",
      "\"Oh the food is sooo good!!\"\n",
      "\"Really? You've eaten there?\"\n",
      "\"No. But all my yuppy friends have and they say it's good so it must be.\"\n",
      "\n",
      "I only give it a two because the service and presentation of the food was decent.\n",
      "\n",
      "We ordered something called oxtail fries which were horrible. I'm sure an actual oxtail would probably have been tastier.\n",
      "\n",
      "My girlfriend and I each ordered a different burger so we could sample each others. Sorry I can't remember what they were called but we didn't care for either one. The best compliment I could pay them is to say they were at least edible.\n",
      "\n",
      "So as mentioned the service was decent and the food looked presentable but as far as taste I can't recommend this place. \n",
      "\n",
      "Perhaps it's just me. Maybe the asian fusion just isn't my type of food. \n",
      "\n",
      "I'd rather have a Wendys burger over this place.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "with codecs.open('review_text_lv_rest_subset_30.txt', encoding='utf_8') as f:\n",
    "    sample_review = list(it.islice(f, 8, 9))[0]\n",
    "    sample_review = sample_review.replace('\\\\n', '\\n')\n",
    "        \n",
    "print(sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper functions from modern nlp in python\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            yield review.replace('\\\\n', '\\n')\n",
    "            \n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_review in nlp.pipe(line_review(filename),\n",
    "                                  batch_size=10000, n_threads=4):\n",
    "        \n",
    "        for sent in parsed_review.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent\n",
    "                             if not punct_space(token)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_sentences_filepath = 'unigram_sentences_all_eat_30.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2d 14h 54min 22s, sys: 1d 16h 18min 7s, total: 4d 7h 12min 29s\n",
      "Wall time: 15h 9min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 1 == 0:\n",
    "    with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for sentence in lemmatized_sentence_corpus('review_text_eats_subset_30.txt'):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17h 53min 55s, sys: 12h 6min 47s, total: 1d 6h 43s\n",
      "Wall time: 4h 29min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 1 == 0:\n",
    "    with codecs.open('unigram_sentences_all_lv_rest_30.txt', 'w', encoding='utf_8') as f:\n",
    "        for sentence in lemmatized_sentence_corpus('review_text_lv_rest_subset_30.txt'):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
