{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#regualr spacy instal lwould not work, had to get from github\n",
    "#conda install -c conda-forge spacy\n",
    "#python -m spacy download en\n",
    "#check with: python -m spacy validate\n",
    "#restart jupyter notebook\n",
    "\n",
    "import codecs\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()\n",
    "#import en_core_web_md\n",
    "#nlp = en_core_web_md.load()\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I live very near this place and have been curious to try it for sometime now as it always seems busy.\n",
      "\n",
      "Well my curiosity has been satisfied and I'm sure I'll never feel the need to visit this place again.\n",
      "\n",
      "It struck me as a typical trendy place that yuppies feel they need to visit as all the other yuppies do.  \n",
      "\"Oh the food is sooo good!!\"\n",
      "\"Really? You've eaten there?\"\n",
      "\"No. But all my yuppy friends have and they say it's good so it must be.\"\n",
      "\n",
      "I only give it a two because the service and presentation of the food was decent.\n",
      "\n",
      "We ordered something called oxtail fries which were horrible. I'm sure an actual oxtail would probably have been tastier.\n",
      "\n",
      "My girlfriend and I each ordered a different burger so we could sample each others. Sorry I can't remember what they were called but we didn't care for either one. The best compliment I could pay them is to say they were at least edible.\n",
      "\n",
      "So as mentioned the service was decent and the food looked presentable but as far as taste I can't recommend this place. \n",
      "\n",
      "Perhaps it's just me. Maybe the asian fusion just isn't my type of food. \n",
      "\n",
      "I'd rather have a Wendys burger over this place.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "with codecs.open('review_text_lv_rest_subset_30.txt', encoding='utf_8') as f:\n",
    "    sample_review = list(it.islice(f, 8, 9))[0]\n",
    "    sample_review = sample_review.replace('\\\\n', '\\n')\n",
    "        \n",
    "print(sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper functions from modern nlp in python\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    \n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def line_review(filename):\n",
    "    \"\"\"\n",
    "    generator function to read in reviews from the file\n",
    "    and un-escape the original line breaks in the text\n",
    "    \"\"\"\n",
    "    \n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            yield review.replace('\\\\n', '\\n')\n",
    "            \n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    \"\"\"\n",
    "    generator function to use spaCy to parse reviews,\n",
    "    lemmatize the text, and yield sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    for parsed_review in nlp.pipe(line_review(filename),\n",
    "                                  batch_size=10000, n_threads=4):\n",
    "        \n",
    "        for sent in parsed_review.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent\n",
    "                             if not punct_space(token)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_sentences_filepath = 'unigram_sentences_all_eat_30.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2d 14h 54min 22s, sys: 1d 16h 18min 7s, total: 4d 7h 12min 29s\n",
      "Wall time: 15h 9min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 1 == 0:\n",
    "    with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        for sentence in lemmatized_sentence_corpus('review_text_eats_subset_30.txt'):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17h 53min 55s, sys: 12h 6min 47s, total: 1d 6h 43s\n",
      "Wall time: 4h 29min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if 1 == 0:\n",
    "    with codecs.open('unigram_sentences_all_lv_rest_30.txt', 'w', encoding='utf_8') as f:\n",
    "        for sentence in lemmatized_sentence_corpus('review_text_lv_rest_subset_30.txt'):\n",
    "            f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_sentences = LineSentence('unigram_sentences_all_lv_rest_30.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the blt be edible\n",
      "\n",
      "the shrimp po boy be not\n",
      "\n",
      "-PRON- be not a picky eater but -PRON- be only able to take two bite of the po boy\n",
      "\n",
      "-PRON- taste like old grease\n",
      "\n",
      "the shrimp be tasteless\n",
      "\n",
      "the waiter stop by and ask how the food be\n",
      "\n",
      "-PRON- tell -PRON- horrible\n",
      "\n",
      "-PRON- just smile and walk away\n",
      "\n",
      "-PRON- think -PRON- must have misheard -PRON- lol\n",
      "\n",
      "other option may be good but -PRON- have only get one shot to make a first impression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for unigram_sentence in it.islice(unigram_sentences, 230, 240):\n",
    "    print( u' '.join(unigram_sentence))\n",
    "    print(u'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_model_filepath = 'bigram_model_lv_rest_30'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 28s, sys: 0 ns, total: 2min 28s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#time consuming\n",
    "if 0 == 1:\n",
    "\n",
    "    bigram_model = Phrases(unigram_sentences)\n",
    "\n",
    "    bigram_model.save(bigram_model_filepath)\n",
    "    \n",
    "# load the finished model from disk\n",
    "bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the finished model from disk\n",
    "bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_sentences_filepath = 'bigram_sentences_lv_rest.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlrognstad/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:486: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 51s, sys: 0 ns, total: 5min 51s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "\n",
    "    with codecs.open(bigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        \n",
    "        for unigram_sentence in unigram_sentences:\n",
    "            \n",
    "            bigram_sentence = u' '.join(bigram_model[unigram_sentence])\n",
    "            \n",
    "            f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_sentences = LineSentence(bigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the blt be edible\n",
      "\n",
      "the shrimp_po boy be not\n",
      "\n",
      "-PRON- be not a picky_eater but -PRON- be only able to take two bite of the po_boy\n",
      "\n",
      "-PRON- taste like old grease\n",
      "\n",
      "the shrimp be tasteless\n",
      "\n",
      "the waiter stop by and ask how the food be\n",
      "\n",
      "-PRON- tell -PRON- horrible\n",
      "\n",
      "-PRON- just smile and walk away\n",
      "\n",
      "-PRON- think -PRON- must have misheard -PRON- lol\n",
      "\n",
      "other option may be good but -PRON- have only get one shot to make a first_impression\n",
      "\n",
      "the impression -PRON- leave will not have -PRON- come back\n",
      "\n",
      "-PRON- have eat here a couple of time\n",
      "\n",
      "great food\n",
      "\n",
      "friendly staff\n",
      "\n",
      "excellent ambiance\n",
      "\n",
      "can not wait to visit here again\n",
      "\n",
      "have grab a quick_bite to eat hear many time as -PRON- be right around the corner from -PRON-\n",
      "\n",
      "always quick and friendly\n",
      "\n",
      "sometimes when -PRON- have -PRON- dog in the car -PRON- even give -PRON- a treat\n",
      "\n",
      "this be one of the good bar in town\n",
      "\n",
      "not many of the yuppie type here\n",
      "\n",
      "thank_god\n",
      "\n",
      "great food friendly staff and customer\n",
      "\n",
      "karaoke night with james be a blast\n",
      "\n",
      "stop in here recently for lunch\n",
      "\n",
      "-PRON- order a chicken sandwich combo to go\n",
      "\n",
      "the two guy work the front counter have the enthusiasm of a couple of rock\n",
      "\n",
      "-PRON- look like -PRON- be an effort for -PRON- to even take a step\n",
      "\n",
      "-PRON- understand -PRON- be probably not the good job in the world\n",
      "\n",
      "but there be people like -PRON- who recruit -PRON- employee from people -PRON- run into during -PRON- day to day activity\n",
      "\n",
      "these two have zero chance of be recruit to work somewhere_else\n",
      "\n",
      "-PRON- also have to ask for the fry that go with -PRON- combo\n",
      "\n",
      "-PRON- get -PRON- but only after a heavy sigh from one of the two at the counter\n",
      "\n",
      "-PRON- would have think -PRON- would ask -PRON- to come outside and change -PRON- tire rather then just ask -PRON- for a bag of fry\n",
      "\n",
      "the food be mediocre probably a three\n",
      "\n",
      "but the lack of enthusiastic service definitely drop -PRON- to a two\n",
      "\n",
      "eat here tonight with -PRON- family\n",
      "\n",
      "-PRON- would not hurt the hostess to learn how to smile now and then\n",
      "\n",
      "the food be good and -PRON- waiter be polite and friendly\n",
      "\n",
      "everything be a bit slow tonight\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bigram_sentence in it.islice(bigram_sentences, 230, 270):\n",
    "    print(u' '.join(bigram_sentence))\n",
    "    print(u'')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_model_filepath = 'trigram_model_lv_rest_30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 1.19 s, total: 2min 21s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute modeling yourself.\n",
    "if 1 == 1:\n",
    "\n",
    "    trigram_model = Phrases(bigram_sentences)\n",
    "\n",
    "    trigram_model.save(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = 'trigram_sentences_lv_rest.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlrognstad/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:486: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 1s, sys: 1.7 s, total: 6min 3s\n",
      "Wall time: 6min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "\n",
    "    with codecs.open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "        \n",
    "        for bigram_sentence in bigram_sentences:\n",
    "            \n",
    "            trigram_sentence = u' '.join(trigram_model[bigram_sentence])\n",
    "            \n",
    "            f.write(trigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the blt be edible\n",
      "\n",
      "the shrimp_po_boy be not\n",
      "\n",
      "-PRON- be not a picky_eater but -PRON- be only able to take two bite of the po_boy\n",
      "\n",
      "-PRON- taste like old grease\n",
      "\n",
      "the shrimp be tasteless\n",
      "\n",
      "the waiter stop by and ask how the food be\n",
      "\n",
      "-PRON- tell -PRON- horrible\n",
      "\n",
      "-PRON- just smile and walk away\n",
      "\n",
      "-PRON- think -PRON- must have misheard -PRON- lol\n",
      "\n",
      "other option may be good but -PRON- have only get one shot to make a first_impression\n",
      "\n",
      "the impression -PRON- leave will not have -PRON- come back\n",
      "\n",
      "-PRON- have eat here a couple of time\n",
      "\n",
      "great food\n",
      "\n",
      "friendly staff\n",
      "\n",
      "excellent ambiance\n",
      "\n",
      "can not wait to visit here again\n",
      "\n",
      "have grab a quick_bite to eat hear many time as -PRON- be right around the corner from -PRON-\n",
      "\n",
      "always quick and friendly\n",
      "\n",
      "sometimes when -PRON- have -PRON- dog in the car -PRON- even give -PRON- a treat\n",
      "\n",
      "this be one of the good bar in town\n",
      "\n",
      "not many of the yuppie type here\n",
      "\n",
      "thank_god\n",
      "\n",
      "great food friendly staff and customer\n",
      "\n",
      "karaoke night with james be a blast\n",
      "\n",
      "stop in here recently for lunch\n",
      "\n",
      "-PRON- order a chicken sandwich combo to go\n",
      "\n",
      "the two guy work the front counter have the enthusiasm of a couple of rock\n",
      "\n",
      "-PRON- look like -PRON- be an effort for -PRON- to even take a step\n",
      "\n",
      "-PRON- understand -PRON- be probably not the good job in the world\n",
      "\n",
      "but there be people like -PRON- who recruit -PRON- employee from people -PRON- run into during -PRON- day to day activity\n",
      "\n",
      "these two have zero chance of be recruit to work somewhere_else\n",
      "\n",
      "-PRON- also have to ask for the fry that go with -PRON- combo\n",
      "\n",
      "-PRON- get -PRON- but only after a heavy sigh from one of the two at the counter\n",
      "\n",
      "-PRON- would have think -PRON- would ask -PRON- to come outside and change -PRON- tire rather then just ask -PRON- for a bag of fry\n",
      "\n",
      "the food be mediocre probably a three\n",
      "\n",
      "but the lack of enthusiastic service definitely drop -PRON- to a two\n",
      "\n",
      "eat here tonight with -PRON- family\n",
      "\n",
      "-PRON- would not hurt the hostess to learn how to smile now and then\n",
      "\n",
      "the food be good and -PRON- waiter be polite and friendly\n",
      "\n",
      "everything be a bit slow tonight\n",
      "\n",
      "wait time for a seat be about 20_minute\n",
      "\n",
      "fortunately the time spend wait for -PRON- food pass quickly as -PRON- spend the time catch up with the family -PRON- have not see in awhile\n",
      "\n",
      "friendly staff\n",
      "\n",
      "clean place\n",
      "\n",
      "visit with one of the employee while wait for -PRON- pizza\n",
      "\n",
      "do not realize how long this business have operate in vegas\n",
      "\n",
      "will definitely be back\n",
      "\n",
      "-PRON- enjoy place that give a bit of history to -PRON-\n",
      "\n",
      "eat here with -PRON- girlfriend this evening\n",
      "\n",
      "-PRON- have the mongolian entree and -PRON- have the pad cha_cha_cha entree\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for trigram_sentence in it.islice(trigram_sentences, 230, 280):\n",
    "    print(u' '.join(trigram_sentence))\n",
    "    print(u'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write the transformed text out to a new file, with one review per line.\n",
    "\n",
    "trigram_reviews_filepath = 'trigram_transformed_reviews_lv_rest.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_txt_filepath = 'review_text_lv_rest_subset_30.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#process reviews\n",
    "\n",
    "%%time\n",
    "\n",
    "# this is a bit time consuming - make the if statement True\n",
    "# if you want to execute data prep yourself.\n",
    "if 1 == 1:\n",
    "\n",
    "    with codecs.open(trigram_reviews_filepath, 'w', encoding='utf_8') as f:\n",
    "        \n",
    "        for parsed_review in nlp.pipe(line_review(review_txt_filepath),\n",
    "                                      batch_size=10000, n_threads=4):\n",
    "            \n",
    "            # lemmatize the text, removing punctuation and whitespace\n",
    "            unigram_review = [token.lemma_ for token in parsed_review\n",
    "                              if not punct_space(token)]\n",
    "            \n",
    "            # apply the first-order and second-order phrase models\n",
    "            bigram_review = bigram_model[unigram_review]\n",
    "            trigram_review = trigram_model[bigram_review]\n",
    "            \n",
    "            # remove any remaining stopwords\n",
    "            trigram_review = [term for term in trigram_review\n",
    "                              if term not in spacy.en.language_data.STOP_WORDS]\n",
    "            \n",
    "            # write the transformed review as a line in the new file\n",
    "            trigram_review = u' '.join(trigram_review)\n",
    "            f.write(trigram_review + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
